# Example configuration for running Replicante with Ollama
# This configuration creates a practical, working AI assistant

# Database location - will be created if it doesn't exist
database_path = "replicante-ollama.db"

[agent]
# Unique identifier for this agent instance
id = "replicante-ollama-assistant"

# Logging level: trace, debug, info, warn, error
log_level = "info"

# Time between reasoning cycles (seconds)
reasoning_interval_secs = 20

# Practical goals for a useful AI assistant
initial_goals = """
You are a helpful AI assistant with access to useful tools. Your goals are:

1. **Provide Information**: Answer questions and help users with calculations, time, and weather
2. **Use Tools Effectively**: Leverage available tools to give accurate, helpful responses
3. **Learn from Experience**: Remember what works to improve future interactions
4. **Stay Helpful**: Focus on providing value through useful services
5. **Be Reliable**: Maintain consistent operation and restart tools when needed

Available capabilities:
- Mathematical calculations (addition, subtraction, multiplication, division, etc.)
- Time information across different timezones
- Weather information (simulated data for demonstration)
- Web data fetching from safe sources
- Simple data processing and echo services

Always aim to be helpful, accurate, and efficient in your responses.
"""

[llm]
# LLM provider configuration for Ollama
provider = "ollama"

# Model to use - llama3.2:3b is fast and efficient
# Other options: llama2:7b, mistral:7b, codellama:7b, phi3:mini
model = "llama3.2:3b"

# Ollama API endpoint (default local installation)
api_url = "http://localhost:11434"

# Temperature for response generation (0.0-1.0, higher = more creative)
temperature = 0.7

# Maximum tokens in response
max_tokens = 2000

# MCP (Model Context Protocol) Servers
# Working tools that provide real functionality

# HTTP Tools Server - provides web requests, calculations, time, weather
[[mcp_servers]]
name = "http-tools"
transport = "stdio"
command = "python"
args = ["-u", "test/http_mcp_server.py"]
retry_attempts = 3
retry_delay_ms = 1500
health_check_interval_secs = 60

# Basic Tools Server - provides echo and simple arithmetic
[[mcp_servers]]
name = "basic-tools"
transport = "stdio"
command = "python"
args = ["-u", "test/mock_mcp_server.py"]
retry_attempts = 2
retry_delay_ms = 1000
health_check_interval_secs = 120

# Add more MCP servers as they become available:
# [[mcp_servers]]
# name = "nostr"
# transport = "stdio"
# command = "mcp-server-nostr"
# args = ["--relay", "wss://relay.damus.io"]
# retry_attempts = 3
# retry_delay_ms = 3000
# health_check_interval_secs = 90

# [[mcp_servers]]
# name = "bitcoin"
# transport = "stdio"
# command = "mcp-server-bitcoin"
# args = ["--network", "testnet"]
# retry_attempts = 3
# retry_delay_ms = 5000
# health_check_interval_secs = 120